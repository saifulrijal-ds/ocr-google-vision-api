{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import google.cloud.vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"sturdy-quarter-361804-599639eb7da1.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image sample [otter crossing](https://storage.googleapis.com/cloud-vision-codelab/otter_crossing.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from google.cloud import vision\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "CAUTION\n",
      "Otters crossing\n",
      "for next 6 miles\n",
      "bounds: (59, 243),(249, 243),(249, 341),(59, 341)\n",
      "==============================\n",
      "CAUTION\n",
      "bounds: (75, 244),(232, 243),(232, 269),(75, 270)\n",
      "==============================\n",
      "Otters\n",
      "bounds: (64, 293),(141, 294),(141, 315),(64, 314)\n",
      "==============================\n",
      "crossing\n",
      "bounds: (150, 294),(248, 295),(248, 316),(150, 315)\n",
      "==============================\n",
      "for\n",
      "bounds: (59, 321),(93, 320),(93, 339),(59, 340)\n",
      "==============================\n",
      "next\n",
      "bounds: (104, 320),(156, 319),(156, 338),(104, 339)\n",
      "==============================\n",
      "6\n",
      "bounds: (166, 320),(178, 320),(178, 338),(166, 338)\n",
      "==============================\n",
      "miles\n",
      "bounds: (189, 319),(249, 318),(249, 337),(189, 338)\n"
     ]
    }
   ],
   "source": [
    "image_uri = 'gs://cloud-vision-codelab/otter_crossing.jpg'\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "image = vision.Image()\n",
    "image.source.image_uri = image_uri\n",
    "\n",
    "response = client.text_detection(image=image)\n",
    "\n",
    "for text in response.text_annotations:\n",
    "    print(\"=\" * 30)\n",
    "    print(text.description)\n",
    "    vertices = ['(%s, %s)' % (v.x, v.y) for v in text.bounding_poly.vertices]\n",
    "    print('bounds:', \",\".join(vertices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "B 6703 WJF\n",
      "07.18\n",
      "bounds: (73, 52),(886, 52),(886, 325),(73, 325)\n",
      "==============================\n",
      "B\n",
      "bounds: (73, 70),(155, 68),(158, 199),(76, 201)\n",
      "==============================\n",
      "6703\n",
      "bounds: (240, 66),(566, 59),(569, 190),(243, 197)\n",
      "==============================\n",
      "WJF\n",
      "bounds: (628, 57),(878, 51),(881, 182),(631, 188)\n",
      "==============================\n",
      "07.18\n",
      "bounds: (510, 245),(885, 245),(885, 316),(510, 316)\n"
     ]
    }
   ],
   "source": [
    "path = \"image_sample/plat1.jpg\"\n",
    "\n",
    "with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "image = vision.Image(content=content)\n",
    "# image.source.image_uri = image_uri\n",
    "\n",
    "response = client.text_detection(image=image)\n",
    "\n",
    "for text in response.text_annotations:\n",
    "    print(\"=\" * 30)\n",
    "    print(text.description)\n",
    "    vertices = ['(%s, %s)' % (v.x, v.y) for v in text.bounding_poly.vertices]\n",
    "    print('bounds:', \",\".join(vertices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "G 1023 XX\n",
      "1\n",
      "bounds: (229, 162),(688, 162),(688, 246),(229, 246)\n",
      "==============================\n",
      "G\n",
      "bounds: (229, 168),(253, 167),(254, 210),(230, 211)\n",
      "==============================\n",
      "1023\n",
      "bounds: (271, 166),(366, 164),(367, 208),(272, 210)\n",
      "==============================\n",
      "XX\n",
      "bounds: (385, 164),(447, 163),(448, 206),(386, 207)\n",
      "==============================\n",
      "1\n",
      "bounds: (689, 226),(688, 246),(661, 245),(662, 225)\n"
     ]
    }
   ],
   "source": [
    "path = \"image_sample/plat2.jpg\"\n",
    "\n",
    "with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "image = vision.Image(content=content)\n",
    "# image.source.image_uri = image_uri\n",
    "\n",
    "response = client.text_detection(image=image)\n",
    "\n",
    "for text in response.text_annotations:\n",
    "    print(\"=\" * 30)\n",
    "    print(text.description)\n",
    "    vertices = ['(%s, %s)' % (v.x, v.y) for v in text.bounding_poly.vertices]\n",
    "    print('bounds:', \",\".join(vertices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('google_api_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "deea89dc16d2377162d5c29059ce6d464bdde775a4da47e1fc4be2a77cf71a8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
